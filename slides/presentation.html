
<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <title>Using Predefined TensorFlow models for Object Detection</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="icon" type="image/x-icon" href="assets/favicon.ico">
  
  <style type="text/css">
  @font-face {
    font-family: 'H5hQWHvoDm';
    src: url(https://slidebean-uploads.s3.amazonaws.com/3436e3686defc176e84e1bbd36bffc44_CuchoBold.otf);
  }
  </style>
  

  <style type="text/css">
  @font-face {
    font-family: 'H5hQWHvoDm';
    src: url(assets/fonts/3436e3686defc176e84e1bbd36bffc44_CuchoBoldotf-XDduhdpy);
  }
  </style>
  
</head>
<body>
  <app-root>
    <div class="main-spinner text-muted">
      <div class="dot"></div>
      <div class="dot"></div>
      <div class="dot"></div>
    </div>

    <style media="screen">
      @-webkit-keyframes dot-fx {
        0%,
        70%,
        100% {
          transform: scale(0);
          opacity: 0;
        }
        35% {
          transform: scale(1);
          opacity: 1;
        }
      }

      @-moz-keyframes dot-fx {
        0%,
        70%,
        100% {
          transform: scale(0);
          opacity: 0;
        }
        35% {
          transform: scale(1);
          opacity: 1;
        }
      }

      @-o-keyframes dot-fx {
        0%,
        70%,
        100% {
          transform: scale(0);
          opacity: 0;
        }
        35% {
          transform: scale(1);
          opacity: 1;
        }
      }

      @keyframes dot-fx {
        0%,
        70%,
        100% {
          transform: scale(0);
          opacity: 0;
        }
        35% {
          transform: scale(1);
          opacity: 1;
        }
      }

      .main-spinner {
        position: fixed;
        left: 50%;
        top: 50%;
        -webkit-transform: translate(-50%, -50%);
           -moz-transform: translate(-50%, -50%);
             -o-transform: translate(-50%, -50%);
                transform: translate(-50%, -50%);

        display: flex;
        flex-flow: row nowrap;
        padding: 0.3em;
      }

      .main-spinner>.dot {
        width: 1.4em;
        height: 1.4em;
        border-width: 0.28em;
        border-style: solid;
        border-color: inherit;
        border-radius: 50%;
        transform: scale(0);
        -webkit-animation: dot-fx 1800ms ease infinite 0ms;
           -moz-animation: dot-fx 1800ms ease infinite 0ms;
             -o-animation: dot-fx 1800ms ease infinite 0ms;
                animation: dot-fx 1800ms ease infinite 0ms;
      }

      .main-spinner>.dot:nth-child(2) {
        margin-left: 0.28em;
        -webkit-animation: dot-fx 1800ms ease infinite 270ms;
           -moz-animation: dot-fx 1800ms ease infinite 270ms;
             -o-animation: dot-fx 1800ms ease infinite 270ms;
                animation: dot-fx 1800ms ease infinite 270ms;
      }

      .main-spinner>.dot:nth-child(3) {
        margin-left: 0.28em;
        -webkit-animation: dot-fx 1800ms ease infinite 540ms;
           -moz-animation: dot-fx 1800ms ease infinite 540ms;
             -o-animation: dot-fx 1800ms ease infinite 540ms;
                animation: dot-fx 1800ms ease infinite 540ms;
      }
    </style>
  </app-root>

  
  <script>
  window.__sb__ = {
    presentation: {"owner":{"__type":"Pointer","className":"_User","objectId":"82kDCytwem"},"layoutStyle":{"createdAt":"2016-08-04T18:12:47.427Z","updatedAt":"2020-05-18T05:15:42.739Z","layoutId":"rapture","label":"Rapture","public":true,"defaultFont":{"__type":"Pointer","className":"Font","objectId":"MCWU6KZ8dL"},"defaultFormula":{"__type":"Pointer","className":"Formula","objectId":"eG9JvOOiTi"},"sampleSlideComponents":[{"type":"heading","data":{"heading":"Stay positive"},"options":{"textSize":3,"xRatio":-0.49,"yRatio":20.32}},{"type":"image","data":{"image":null,"icon":{"source":"NounProject","id":"900888","thumbnailUrl":"https://d30y9cdsu7xlg0.cloudfront.net/png/900888-200.png"}},"options":{"size":1,"xRatio":0,"yRatio":0}},{"type":"quote","data":{"quote":"Passion never fails","author":"Paul Chen"},"options":{"textSize":2.2,"xRatio":-13.27,"yRatio":97.17}}],"defaultSlideOptions":{"backgroundFill":"radial"},"defaultElementVariations":{"heading":"Retro","icon":"Ring","number":"Ring"},"evoSampleSlideComponents":[{"id":"xw51e6t3k","type":"heading","data":{"heading":"<p>That's all I gotta say about that</p>"},"options":{"textSize":3,"xRatio":0,"yRatio":-6.62},"style":{"x":0.0625,"y":0.15000000000000002,"w":0.75,"h":0.15000000000000002,"z":16}},{"id":"7435fg0rn","type":"image","data":{"image":null,"icon":{"source":"NounProject","id":"102650","thumbnailUrl":"https://d30y9cdsu7xlg0.cloudfront.net/png/102650-200.png"}},"options":{"size":0.8,"xRatio":-1.5,"yRatio":-4.36},"style":{"x":0.0625,"y":0.37499999999999994,"w":0.25,"h":0.4,"z":18}},{"id":"3h2oe96i0","type":"quote","data":{"quote":"<p>My mom always said life was like a box of chocolates. You never know what you're gonna get.</p>","author":"<p><b>Forrest Gump</b></p>"},"options":{"textSize":2.2,"xRatio":-11.88,"yRatio":51.31},"style":{"x":0.3420706417248845,"y":0.42500002970562517,"w":0.59375,"h":0.3,"z":19}}],"ACL":{"*":{"read":true}},"objectId":"ZZZhxHW8MY","__type":"Object","className":"Layout"},"colorPalette":{"colorSets":[{"back":"#ffffff","text":"#004c80","highlight":"#0b8730"},{"back":"#ffffff","text":"#0585dd","highlight":"#f19400"}],"label":"Tan Vu","owner":{"__type":"Pointer","className":"_User","objectId":"82kDCytwem"},"createdAt":"2018-04-05T19:36:53.852Z","updatedAt":"2018-04-05T20:27:12.390Z","ACL":{"*":{"read":true},"role:Team":{"write":true},"82kDCytwem":{"write":true}},"objectId":"xzAOuxaJ0Z","__type":"Object","className":"Palette"},"privacy":"unlisted","views":1,"titlePlain":"Using Predefined TensorFlow models for Object Detection","createdAt":"2018-03-24T09:25:34.868Z","updatedAt":"2020-06-03T19:15:04.341Z","formula":{"owner":{"__type":"Pointer","className":"_User","objectId":"82kDCytwem"},"name":"Tan Vu","layoutStyle":{"__type":"Pointer","className":"Layout","objectId":"ZZZhxHW8MY"},"colorPalette":{"__type":"Pointer","className":"Palette","objectId":"xzAOuxaJ0Z"},"textFont":{"__type":"Pointer","className":"Font","objectId":"MagMAEDrGL"},"headingFont":{"__type":"Pointer","className":"Font","objectId":"H5hQWHvoDm"},"logoFileLightBackgrounds":{"__type":"File","name":"3c72bef3a5e9f5aa2b8e7cd3a8f43f16_profileround.png","url":"https://slidebean-uploads.s3.amazonaws.com/3c72bef3a5e9f5aa2b8e7cd3a8f43f16_profileround.png"},"suggestedPalette":{"__type":"Pointer","className":"Palette","objectId":"xzAOuxaJ0Z"},"logoFileDarkBackgrounds":{"__type":"File","name":"31be2e2278a777658e6a0bfee6b348c8_profileround.png","url":"https://slidebean-uploads.s3.amazonaws.com/31be2e2278a777658e6a0bfee6b348c8_profileround.png"},"createdAt":"2018-04-05T19:53:22.995Z","updatedAt":"2018-04-05T20:02:07.074Z","ACL":{"*":{"read":true},"role:Team":{"write":true},"82kDCytwem":{"write":true}},"objectId":"O1HLTZWQAD","__type":"Object","className":"Formula"},"textFont":{"owner":{"__type":"Pointer","className":"_User","objectId":"82kDCytwem"},"label":"r0c0i - Linotte Regular","fontFile":{"__type":"File","name":"ec76ce9cfab92c4adcb9ad21cd62aadb_r0c0iLinotteRegular.ttf","url":"assets/fonts/ec76ce9cfab92c4adcb9ad21cd62aadb_r0c0iLi-qi5Rszsk"},"createdAt":"2018-03-23T17:02:09.695Z","updatedAt":"2019-04-14T17:23:27.130Z","hiddenFromEditor":true,"ACL":{"*":{"read":true},"role:Team":{"write":true},"82kDCytwem":{"write":true}},"objectId":"MagMAEDrGL","__type":"Object","className":"Font"},"headingFont":{"owner":{"__type":"Pointer","className":"_User","objectId":"82kDCytwem"},"label":"Cucho Bold","fontFile":{"__type":"File","name":"3436e3686defc176e84e1bbd36bffc44_CuchoBold.otf","url":"assets/fonts/3436e3686defc176e84e1bbd36bffc44_CuchoBoldotf-XDduhdpy"},"createdAt":"2018-03-23T17:03:23.041Z","updatedAt":"2019-04-14T17:22:57.824Z","hiddenFromEditor":true,"ACL":{"*":{"read":true},"role:Team":{"write":true},"82kDCytwem":{"write":true}},"objectId":"H5hQWHvoDm","__type":"Object","className":"Font"},"logoFileLightBackgrounds":{"__type":"File","name":"3c72bef3a5e9f5aa2b8e7cd3a8f43f16_profileround.png","url":"https://slidebean-uploads.s3.amazonaws.com/3c72bef3a5e9f5aa2b8e7cd3a8f43f16_profileround.png"},"logoFileDarkBackgrounds":{"__type":"File","name":"31be2e2278a777658e6a0bfee6b348c8_profileround.png","url":"https://slidebean-uploads.s3.amazonaws.com/31be2e2278a777658e6a0bfee6b348c8_profileround.png"},"components":[{"type":"cover","data":{"title":"Using Predefined TensorFlow models for Object Detection","subtitle":"","author":"Tan Vu"},"options":{"textSize":0.8,"xRatio":0,"yRatio":0}},{"type":"background","data":{"image":{"url":"https://images.unsplash.com/photo-1513542789411-b6a5d4f31634?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=1080&fit=max&ixid=eyJhcHBfaWQiOjIwMzcxfQ&s=31d01e73142f205bcc64e42ea2e0c6b6","thumbnailUrl":"https://images.unsplash.com/photo-1513542789411-b6a5d4f31634?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=200&fit=max&ixid=eyJhcHBfaWQiOjIwMzcxfQ&s=b1f749e0cb8a1c9fa15334817a70b161","source":"Unsplash","id":"l3N9Q27zULw","name":null,"owner":"designedbyjess","ownerName":"Jess Watters","ownerId":"5KvTlhS8W94","usageReportUrl":"https://api.unsplash.com/photos/l3N9Q27zULw/download?client_id=64d34c0d4b13e39fcc76c60a7f874b20746ab70331c32d6ab3444d9ed2dba794"},"icon":null},"options":{}}],"lastChange":{"__type":"Date","iso":"2020-06-03T19:15:04.349Z"},"title":"Using Predefined TensorFlow models for Object Detection","subtitle":"","author":"Tan Vu","slides":10,"options":{"colorSet":"default","backgroundDim":0,"cropBackground":true,"animate":true,"logoPosition":"top-right"},"isTemplate":true,"templateUsageCount":4,"slideArray":[{"id":"vECRwIIfbz","elements":[{"id":"6e7c9ddc-162f-4fba-b5ed-80b87c4e77b3","type":"cover","data":{"title":"Using Predefined TensorFlow models for Object Detection","subtitle":"","author":"Tan Vu"},"options":{"textSize":0.8,"xRatio":0,"yRatio":0},"style":{}},{"id":"6abd6cd7-52db-4500-8ecd-c276a666bf82","type":"background","data":{"image":{"url":"https://images.unsplash.com/photo-1513542789411-b6a5d4f31634?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=1080&fit=max&ixid=eyJhcHBfaWQiOjIwMzcxfQ&s=31d01e73142f205bcc64e42ea2e0c6b6","thumbnailUrl":"https://images.unsplash.com/photo-1513542789411-b6a5d4f31634?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=200&fit=max&ixid=eyJhcHBfaWQiOjIwMzcxfQ&s=b1f749e0cb8a1c9fa15334817a70b161","source":"Unsplash","id":"l3N9Q27zULw","name":null,"owner":"designedbyjess","ownerName":"Jess Watters","ownerId":"5KvTlhS8W94","usageReportUrl":"https://api.unsplash.com/photos/l3N9Q27zULw/download?client_id=64d34c0d4b13e39fcc76c60a7f874b20746ab70331c32d6ab3444d9ed2dba794"},"icon":null},"options":{},"style":{}}],"options":{"colorSet":"default","backgroundDim":0,"cropBackground":true,"animate":true,"logoPosition":"top-right"},"notes":"","hasBeenManuallyArranged":false},{"id":"DE9bk3u8cO","elements":[{"id":"68935180-b85b-4503-b97e-31fe11b89f11","type":"heading","data":{"heading":"Requirements"},"options":{},"style":{}},{"id":"ea165ef3-34e2-4a64-b512-139f40987f30","type":"paragraph","data":{"paragraph":"<ul><li>What we need for the object detection:<ul><li>TensorFlow - GPU (CPU is not practical for this kind of application). Here I will train the network using my GTX 970M on my laptop. It's not too good, but better than CPU.</li><li>Gather and Label images for training and testing.</li><li>The <a rel=\"nofollow noopener noreferrer\" target=\"_blank\" href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\">models</a> from TensorFlow.</li></ul></li></ul>"},"options":{"textAlign":"left","textSize":0},"style":{}}],"options":{},"notes":"","hasBeenManuallyArranged":false},{"id":"hIOBigLfvZ","elements":[{"id":"3d937509-7aa0-4ad0-a97a-e7d5a9c97e9b","type":"heading","data":{"heading":"Install predefined models"},"options":{},"style":{}},{"id":"f91896f8-44fd-4a61-b8b0-8ab66b4e5115","type":"paragraph","data":{"paragraph":"<ul><li>First, we need to download TensorFlow's model <a rel=\"nofollow noopener noreferrer\" target=\"_blank\" href=\"https://github.com/tensorflow/models\">repository</a>.<br></li><li>From the model zoo, we need to select a pre-built model that we want to use for our object detection model<ul><li>Depending on the complexity of the model, the speed and accuracy might be different.</li></ul></li><li>In this tutorial, we will use the <b>faster_rcnn_inception_v2.coco </b>model.<ul><li>First download the archive file from the model zoo.</li><li>After downloading, extract the folder to \"models/research/object_detection\" where \"models\" is the TensorFlow's repository.</li></ul></li></ul>"},"options":{},"style":{}},{"id":"2ee0f227-cad4-4467-b2af-74347cd58485","type":"image","data":{"image":{"url":"https://slidebean-uploads.s3.amazonaws.com/40149cd0ad9f6cb1a3ba39826e0997a3_Image20180324at11.02.08AM.png"},"icon":null},"options":{},"style":{}}],"options":{},"notes":"","hasBeenManuallyArranged":false},{"id":"yxCC65cUhU","elements":[{"id":"6eda80ac-b116-4226-b07d-421301151536","type":"heading","data":{"heading":"Pre-built model folder"},"options":{},"style":{}},{"id":"ff463ab5-3487-4277-a928-1a7510ae017a","type":"image","data":{"image":{"url":"https://slidebean-uploads.s3.amazonaws.com/515fef97eadf9e82dcec3cc862b3fd7c_Image20180324at11.08.53AM.png"},"icon":null},"options":{"size":2,"imageCrop":"contain"},"style":{}},{"id":"f310ed45-2d3f-4fad-8e3a-55d1f7a317bb","type":"paragraph","data":{"paragraph":"<ul><li><div><p>All of TensorFlow's file formats are based on <a rel=\"nofollow noopener noreferrer\" target=\"_blank\" href=\"https://developers.google.com/protocol-buffers/?hl=en\">Protocol Buffers</a></p></div></li><li><p>saved_model folder includes the protobuf file which is used to store the network definition from TensorFlow. We need to load the predefined network to our model.</p></li></ul>"},"options":{},"style":{}}],"options":{},"notes":"","hasBeenManuallyArranged":false},{"id":"AO7yowbKBs","elements":[{"id":"00d3cc9f-836e-4323-93e9-6e64aa5e4480","type":"heading","data":{"heading":"Dependencies"},"options":{},"style":{}},{"id":"02f6aff6-cf4b-4c1d-a733-c210db67a84b","type":"paragraph","data":{"paragraph":"<ul><li>tensorflow-gpu</li><li>protobuf</li><li>pillow</li><li>lxml</li><li>jupyter</li><li>matplotlib</li><li>pandas</li><li>OpenCV</li></ul>"},"options":{"textAlign":"left"},"style":{}}],"options":{},"notes":"","hasBeenManuallyArranged":false},{"id":"xvmuoCxmF5","elements":[{"id":"765f0ecf-26a1-4176-9e2a-23896000b392","type":"heading","data":{"heading":"Set Environment variables"},"options":{},"style":{}},{"id":"b02c83de-0aa4-46b4-9de3-44db8df776e0","type":"paragraph","data":{"paragraph":"<ul><li>We need to set the python path to the models directory:</li></ul>"},"options":{},"style":{}},{"id":"6579295d-cbb3-49e2-9f1c-42d8baf969d2","type":"image","data":{"image":{"url":"https://slidebean-uploads.s3.amazonaws.com/2aaf77d541fc5877d379ab627a9f2ef1_Image20180324at3.46.12PM.png"},"icon":null},"options":{"size":4,"imageCrop":"contain","textSize":-1},"style":{}}],"options":{"body-layout_2":"b"},"notes":"","hasBeenManuallyArranged":false},{"id":"AGfGStmfLB","elements":[{"id":"788eabea-bb08-4e85-a075-e9b9caec2586","type":"heading","data":{"heading":"Compile Protobufs"},"options":{},"style":{}},{"id":"7510ade9-821f-4688-a473-b963babeb63b","type":"paragraph","data":{"paragraph":"<ul><li>The Protobuf files need to be compiled, which are then used by TensorFlow to configure model and training parameters.</li><li>The instruction from TensorFlow (\n\nprotoc object_detection/protos/*.proto --python_out=.) cannot be used on Windows, so we need to run a for loop to compile all the Protobufs:</li></ul>"},"options":{},"style":{}},{"id":"bdc7861c-650a-435a-83b3-a8002101e65f","type":"code","data":{"code":"for %i in (object_detection\\protos\\*.proto) do (protoc %i --python_out=.)","language":"bash"},"options":{},"style":{}}],"options":{"body-layout_2":"b"},"notes":"","hasBeenManuallyArranged":false},{"id":"RNGjWjJ5AO","elements":[{"id":"40416f0b-d827-4139-bf8b-6fe91e7ff911","type":"heading","data":{"heading":"Using tutorial notebook"},"options":{},"style":{}},{"id":"e8585e25-2700-45a5-a031-6a8456dff8cc","type":"paragraph","data":{"paragraph":"<ul><li>After installing the dependencies, we can now navigate to the \"models\\research\\obect_detection\" folder, and use the tutorial notebook from tensorflow: object_detection_tutorial.ipynb</li><li>We can select one of the models <a rel=\"nofollow noopener noreferrer\" target=\"_blank\" href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\">here</a>&nbsp;to use in object detection model. Remember the trade-off between Speed and Accuracy.</li><li>We will use \"\n\n<a rel=\"nofollow noopener noreferrer\" target=\"_blank\" href=\"http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz\">faster_rcnn_inception_v2_coco</a>\" in this tutorial.</li><li>Running the notebook gives you the output prediction from the \"Pre-trained\" for some test images.</li><li>In this tutorial, we want to train from scratch.</li></ul>"},"options":{"textAlign":"left"},"style":{}}],"options":{"body-layout_2":"b"},"notes":"","hasBeenManuallyArranged":false},{"id":"1rWw8JGCDG","elements":[{"id":"206b963e-da48-42f7-89da-4136857937b1","type":"heading","data":{"heading":"Preparing Images and Labels for training"},"options":{},"style":{}},{"id":"369f048a-919f-41ee-a1cb-fb467695e92b","type":"paragraph","data":{"paragraph":"<ul><li>Now we have finished setting up the environment and TensorFlow.</li><li>We now need to gather images and labels if we want to recognize something from our own.</li><li>One good tool for labeling can be downloaded <a rel=\"nofollow noopener noreferrer\" target=\"_blank\" href=\"https://github.com/tzutalin/labelImg\">here</a><br></li><li>In this first try, I will use&nbsp;Penn-Fudan-Pedestrian dataset for training.</li></ul>"},"options":{"textAlign":"left"},"style":{}}],"options":{},"notes":"","hasBeenManuallyArranged":false},{"id":"cpVyYTqqxE","elements":[{"id":"8873328a-e619-44ea-93f1-8e42dc1d4c19","type":"heading","data":{"heading":""},"options":{},"style":{}},{"id":"277d862a-174e-4dcc-aa58-d99a475441b8","type":"code","data":{"code":"python export_inference_graph.py --input_type image_tensor --pipeline_config_path E:/gt-arc/pedestrian_detection/training/ssd_mobilenet_v1_pets.config --trained_checkpoint_prefix E:/gt-arc/pedestrian_detection/training/model.ckpt-11921 --output_directory E:/gt-arc/pedestrian_detection/inference_graph","language":"bash"},"options":{},"style":{}}],"options":{},"notes":"","hasBeenManuallyArranged":false}],"slideArrayFirst":{"id":"vECRwIIfbz","elements":[{"id":"6e7c9ddc-162f-4fba-b5ed-80b87c4e77b3","type":"cover","data":{"title":"Using Predefined TensorFlow models for Object Detection","subtitle":"","author":"Tan Vu"},"options":{"textSize":0.8,"xRatio":0,"yRatio":0},"style":{}},{"id":"6abd6cd7-52db-4500-8ecd-c276a666bf82","type":"background","data":{"image":{"url":"https://images.unsplash.com/photo-1513542789411-b6a5d4f31634?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=1080&fit=max&ixid=eyJhcHBfaWQiOjIwMzcxfQ&s=31d01e73142f205bcc64e42ea2e0c6b6","thumbnailUrl":"https://images.unsplash.com/photo-1513542789411-b6a5d4f31634?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=200&fit=max&ixid=eyJhcHBfaWQiOjIwMzcxfQ&s=b1f749e0cb8a1c9fa15334817a70b161","source":"Unsplash","id":"l3N9Q27zULw","name":null,"owner":"designedbyjess","ownerName":"Jess Watters","ownerId":"5KvTlhS8W94","usageReportUrl":"https://api.unsplash.com/photos/l3N9Q27zULw/download?client_id=64d34c0d4b13e39fcc76c60a7f874b20746ab70331c32d6ab3444d9ed2dba794"},"icon":null},"options":{},"style":{}}],"options":{"colorSet":"default","backgroundDim":0,"cropBackground":true,"animate":true,"logoPosition":"top-right"},"notes":"","hasBeenManuallyArranged":false},"ACL":{"82kDCytwem":{"read":true,"write":true},"role:Readers_vECRwIIfbz":{"read":true},"role:Writers_vECRwIIfbz":{"read":true,"write":true},"*":{"read":true}},"objectId":"vECRwIIfbz","className":"Presentation"},
    slides: [{"id":"vECRwIIfbz","elements":[{"id":"6e7c9ddc-162f-4fba-b5ed-80b87c4e77b3","type":"cover","data":{"title":"Using Predefined TensorFlow models for Object Detection","subtitle":"","author":"Tan Vu"},"options":{"textSize":0.8,"xRatio":0,"yRatio":0},"style":{}},{"id":"6abd6cd7-52db-4500-8ecd-c276a666bf82","type":"background","data":{"image":{"url":"assets/img/photo-1513542789411-b6a5d4f31634-aakg8oVm","thumbnailUrl":"https://images.unsplash.com/photo-1513542789411-b6a5d4f31634?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=200&fit=max&ixid=eyJhcHBfaWQiOjIwMzcxfQ&s=b1f749e0cb8a1c9fa15334817a70b161","source":"Unsplash","id":"l3N9Q27zULw","name":null,"owner":"designedbyjess","ownerName":"Jess Watters","ownerId":"5KvTlhS8W94","usageReportUrl":"https://api.unsplash.com/photos/l3N9Q27zULw/download?client_id=64d34c0d4b13e39fcc76c60a7f874b20746ab70331c32d6ab3444d9ed2dba794"},"icon":null},"options":{},"style":{}}],"options":{"colorSet":"default","backgroundDim":0,"cropBackground":true,"animate":true,"logoPosition":"top-right"},"notes":"","hasBeenManuallyArranged":false},{"id":"DE9bk3u8cO","elements":[{"id":"68935180-b85b-4503-b97e-31fe11b89f11","type":"heading","data":{"heading":"Requirements"},"options":{},"style":{}},{"id":"ea165ef3-34e2-4a64-b512-139f40987f30","type":"paragraph","data":{"paragraph":"<ul><li>What we need for the object detection:<ul><li>TensorFlow - GPU (CPU is not practical for this kind of application). Here I will train the network using my GTX 970M on my laptop. It's not too good, but better than CPU.</li><li>Gather and Label images for training and testing.</li><li>The <a rel=\"nofollow noopener noreferrer\" target=\"_blank\" href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\">models</a> from TensorFlow.</li></ul></li></ul>"},"options":{"textAlign":"left","textSize":0},"style":{}}],"options":{},"notes":"","hasBeenManuallyArranged":false},{"id":"hIOBigLfvZ","elements":[{"id":"3d937509-7aa0-4ad0-a97a-e7d5a9c97e9b","type":"heading","data":{"heading":"Install predefined models"},"options":{},"style":{}},{"id":"f91896f8-44fd-4a61-b8b0-8ab66b4e5115","type":"paragraph","data":{"paragraph":"<ul><li>First, we need to download TensorFlow's model <a rel=\"nofollow noopener noreferrer\" target=\"_blank\" href=\"https://github.com/tensorflow/models\">repository</a>.<br></li><li>From the model zoo, we need to select a pre-built model that we want to use for our object detection model<ul><li>Depending on the complexity of the model, the speed and accuracy might be different.</li></ul></li><li>In this tutorial, we will use the <b>faster_rcnn_inception_v2.coco </b>model.<ul><li>First download the archive file from the model zoo.</li><li>After downloading, extract the folder to \"models/research/object_detection\" where \"models\" is the TensorFlow's repository.</li></ul></li></ul>"},"options":{},"style":{}},{"id":"2ee0f227-cad4-4467-b2af-74347cd58485","type":"image","data":{"image":{"url":"assets/img/40149cd0ad9f6cb1a3ba39826e0997a3_Image20-JeJAzWOV.png"},"icon":null},"options":{},"style":{}}],"options":{},"notes":"","hasBeenManuallyArranged":false},{"id":"yxCC65cUhU","elements":[{"id":"6eda80ac-b116-4226-b07d-421301151536","type":"heading","data":{"heading":"Pre-built model folder"},"options":{},"style":{}},{"id":"ff463ab5-3487-4277-a928-1a7510ae017a","type":"image","data":{"image":{"url":"assets/img/515fef97eadf9e82dcec3cc862b3fd7c_Image20-1cBakWV5.png"},"icon":null},"options":{"size":2,"imageCrop":"contain"},"style":{}},{"id":"f310ed45-2d3f-4fad-8e3a-55d1f7a317bb","type":"paragraph","data":{"paragraph":"<ul><li><div><p>All of TensorFlow's file formats are based on <a rel=\"nofollow noopener noreferrer\" target=\"_blank\" href=\"https://developers.google.com/protocol-buffers/?hl=en\">Protocol Buffers</a></p></div></li><li><p>saved_model folder includes the protobuf file which is used to store the network definition from TensorFlow. We need to load the predefined network to our model.</p></li></ul>"},"options":{},"style":{}}],"options":{},"notes":"","hasBeenManuallyArranged":false},{"id":"AO7yowbKBs","elements":[{"id":"00d3cc9f-836e-4323-93e9-6e64aa5e4480","type":"heading","data":{"heading":"Dependencies"},"options":{},"style":{}},{"id":"02f6aff6-cf4b-4c1d-a733-c210db67a84b","type":"paragraph","data":{"paragraph":"<ul><li>tensorflow-gpu</li><li>protobuf</li><li>pillow</li><li>lxml</li><li>jupyter</li><li>matplotlib</li><li>pandas</li><li>OpenCV</li></ul>"},"options":{"textAlign":"left"},"style":{}}],"options":{},"notes":"","hasBeenManuallyArranged":false},{"id":"xvmuoCxmF5","elements":[{"id":"765f0ecf-26a1-4176-9e2a-23896000b392","type":"heading","data":{"heading":"Set Environment variables"},"options":{},"style":{}},{"id":"b02c83de-0aa4-46b4-9de3-44db8df776e0","type":"paragraph","data":{"paragraph":"<ul><li>We need to set the python path to the models directory:</li></ul>"},"options":{},"style":{}},{"id":"6579295d-cbb3-49e2-9f1c-42d8baf969d2","type":"image","data":{"image":{"url":"assets/img/2aaf77d541fc5877d379ab627a9f2ef1_Image20-olQnsH8l.png"},"icon":null},"options":{"size":4,"imageCrop":"contain","textSize":-1},"style":{}}],"options":{"body-layout_2":"b"},"notes":"","hasBeenManuallyArranged":false},{"id":"AGfGStmfLB","elements":[{"id":"788eabea-bb08-4e85-a075-e9b9caec2586","type":"heading","data":{"heading":"Compile Protobufs"},"options":{},"style":{}},{"id":"7510ade9-821f-4688-a473-b963babeb63b","type":"paragraph","data":{"paragraph":"<ul><li>The Protobuf files need to be compiled, which are then used by TensorFlow to configure model and training parameters.</li><li>The instruction from TensorFlow (\n\nprotoc object_detection/protos/*.proto --python_out=.) cannot be used on Windows, so we need to run a for loop to compile all the Protobufs:</li></ul>"},"options":{},"style":{}},{"id":"bdc7861c-650a-435a-83b3-a8002101e65f","type":"code","data":{"code":"for %i in (object_detection\\protos\\*.proto) do (protoc %i --python_out=.)","language":"bash"},"options":{},"style":{}}],"options":{"body-layout_2":"b"},"notes":"","hasBeenManuallyArranged":false},{"id":"RNGjWjJ5AO","elements":[{"id":"40416f0b-d827-4139-bf8b-6fe91e7ff911","type":"heading","data":{"heading":"Using tutorial notebook"},"options":{},"style":{}},{"id":"e8585e25-2700-45a5-a031-6a8456dff8cc","type":"paragraph","data":{"paragraph":"<ul><li>After installing the dependencies, we can now navigate to the \"models\\research\\obect_detection\" folder, and use the tutorial notebook from tensorflow: object_detection_tutorial.ipynb</li><li>We can select one of the models <a rel=\"nofollow noopener noreferrer\" target=\"_blank\" href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\">here</a>&nbsp;to use in object detection model. Remember the trade-off between Speed and Accuracy.</li><li>We will use \"\n\n<a rel=\"nofollow noopener noreferrer\" target=\"_blank\" href=\"http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz\">faster_rcnn_inception_v2_coco</a>\" in this tutorial.</li><li>Running the notebook gives you the output prediction from the \"Pre-trained\" for some test images.</li><li>In this tutorial, we want to train from scratch.</li></ul>"},"options":{"textAlign":"left"},"style":{}}],"options":{"body-layout_2":"b"},"notes":"","hasBeenManuallyArranged":false},{"id":"1rWw8JGCDG","elements":[{"id":"206b963e-da48-42f7-89da-4136857937b1","type":"heading","data":{"heading":"Preparing Images and Labels for training"},"options":{},"style":{}},{"id":"369f048a-919f-41ee-a1cb-fb467695e92b","type":"paragraph","data":{"paragraph":"<ul><li>Now we have finished setting up the environment and TensorFlow.</li><li>We now need to gather images and labels if we want to recognize something from our own.</li><li>One good tool for labeling can be downloaded <a rel=\"nofollow noopener noreferrer\" target=\"_blank\" href=\"https://github.com/tzutalin/labelImg\">here</a><br></li><li>In this first try, I will use&nbsp;Penn-Fudan-Pedestrian dataset for training.</li></ul>"},"options":{"textAlign":"left"},"style":{}}],"options":{},"notes":"","hasBeenManuallyArranged":false},{"id":"cpVyYTqqxE","elements":[{"id":"8873328a-e619-44ea-93f1-8e42dc1d4c19","type":"heading","data":{"heading":""},"options":{},"style":{}},{"id":"277d862a-174e-4dcc-aa58-d99a475441b8","type":"code","data":{"code":"python export_inference_graph.py --input_type image_tensor --pipeline_config_path E:/gt-arc/pedestrian_detection/training/ssd_mobilenet_v1_pets.config --trained_checkpoint_prefix E:/gt-arc/pedestrian_detection/training/model.ckpt-11921 --output_directory E:/gt-arc/pedestrian_detection/inference_graph","language":"bash"},"options":{},"style":{}}],"options":{},"notes":"","hasBeenManuallyArranged":false}]
  };
  </script>
  
  <div id="embedded-icons"></div>
  <script type="text/javascript" src="assets/js/runtime.js"></script>
  <script type="text/javascript" src="assets/js/polyfills.js"></script>
  <script type="text/javascript" src="assets/js/scripts.js"></script>
  <script type="text/javascript" src="assets/js/styles.js"></script>
  <script type="text/javascript" src="assets/js/vendor.js"></script>
  <script type="text/javascript" src="assets/js/main.js"></script>
</body>
</html>
